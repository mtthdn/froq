#!/usr/bin/env python3
"""
Normalizer: FaceBase (DERIVA REST API) -> model/facebase.cue

Queries the FaceBase DERIVA catalog for datasets matching each gene symbol
in dataset titles (case-insensitive regex). Falls back to a bundled cache
file if the API is unreachable.

FaceBase (facebase.org) is an NIDCR-funded data repository for craniofacial
research, built on the DERIVA platform. Many of our 20 neural crest genes
have associated datasets (microCT, RNA-seq, scRNA-seq, enhancer assays).

Source-owned fields:
  - _in_facebase: true
  - facebase_id: DERIVA RID of the first dataset
  - facebase_datasets: [{title, species, assay_type}, ...]
"""

import json
import os
import sys
import time

import requests

# Resolve import path for sibling module
sys.path.insert(0, os.path.dirname(__file__))
from genes import GENES

# DERIVA REST API — case-insensitive regex search on dataset title
FACEBASE_URL = "https://www.facebase.org/ermrest/catalog/1/entity/isa:dataset/title::ciregexp::{gene}"
TIMEOUT_SEC = 20
SLEEP_SEC = 0.5
MAX_DATASETS = 5  # Cap per gene to keep CUE output readable

CACHE_PATH = os.path.join(os.path.dirname(__file__), "..", "data", "facebase", "facebase_cache.json")
OUTPUT_PATH = os.path.join(os.path.dirname(__file__), "..", "model", "facebase.cue")


def load_cache() -> dict:
    """Load the bundled fallback cache file."""
    path = os.path.normpath(CACHE_PATH)
    if not os.path.exists(path):
        print(f"  WARNING: cache file not found at {path}", file=sys.stderr)
        return {}
    with open(path) as f:
        return json.load(f)


def fetch_datasets(gene_symbol: str) -> list[dict] | None:
    """Query FaceBase DERIVA API for datasets matching the gene symbol in title."""
    url = FACEBASE_URL.format(gene=gene_symbol)
    headers = {"Accept": "application/json"}
    try:
        resp = requests.get(url, headers=headers, timeout=TIMEOUT_SEC)
        resp.raise_for_status()
        raw = resp.json()
        if not isinstance(raw, list):
            return None
        # Filter: ensure the gene symbol actually appears in the title
        # (ciregexp is broad — "EVC" would also match "sEVCe" etc.)
        filtered = []
        sym_lower = gene_symbol.lower()
        for ds in raw:
            title = (ds.get("title") or "").lower()
            # Match whole-word-ish: gene symbol bounded by non-alpha chars or string edges
            import re
            if re.search(r'(?<![a-z])' + re.escape(sym_lower) + r'(?![a-z0-9])', title):
                filtered.append(ds)
        return filtered
    except requests.RequestException as e:
        print(f"  WARNING: API error for {gene_symbol}: {e}", file=sys.stderr)
        return None


def normalize_dataset(ds: dict) -> dict:
    """Extract the fields we care about from a raw DERIVA dataset record."""
    return {
        "RID": ds.get("RID", ""),
        "accession": ds.get("accession", ""),
        "title": ds.get("title", ""),
        "species": "Mus musculus",  # FaceBase is predominantly mouse
        "assay_type": infer_assay_type(ds.get("title", ""), ds.get("summary", "")),
    }


def infer_assay_type(title: str, summary: str) -> str:
    """Best-effort inference of assay type from title and summary text."""
    text = (title + " " + (summary or "")).lower()
    if "scrna-seq" in text or "single cell" in text or "single-cell" in text:
        return "scRNA-seq"
    if "rna-seq" in text or "rna seq" in text or "rnaseq" in text:
        return "RNA-seq"
    if "chip-seq" in text or "chipseq" in text:
        return "ChIP-seq"
    if "atac-seq" in text or "atacseq" in text:
        return "ATAC-seq"
    if "microct" in text or "micro-ct" in text or "micro ct" in text:
        return "microCT"
    if "micromri" in text or "micro-mri" in text or "micro mri" in text:
        return "microMRI"
    if "enhancer" in text:
        return "enhancer assay"
    if "morphology" in text or "musmorph" in text:
        return "morphology"
    if "gene summary" in text:
        return "gene summary"
    if "hcr" in text or "in situ" in text:
        return "imaging"
    if "suture" in text:
        return "RNA-seq"
    return "other"


def escape_cue_string(s: str) -> str:
    """Escape a string for CUE literal embedding."""
    return s.replace("\\", "\\\\").replace('"', '\\"')


def format_cue(gene_data: dict[str, dict]) -> str:
    """Format the collected gene data as a CUE file."""
    lines = [
        "package froq",
        "",
        "// FaceBase craniofacial research datasets (DERIVA catalog).",
        "// Auto-generated by normalizers/from_facebase.py — do not hand-edit.",
        "",
    ]

    for symbol in sorted(gene_data.keys()):
        entry = gene_data[symbol]
        lines.append(f'genes: "{symbol}": {{')
        lines.append(f"\t_in_facebase: true")
        lines.append(f'\tfacebase_id:  "{escape_cue_string(entry["facebase_id"])}"')

        datasets = entry["datasets"]
        if datasets:
            lines.append(f"\tfacebase_datasets: [")
            for ds in datasets:
                title = escape_cue_string(ds["title"])
                species = escape_cue_string(ds.get("species", ""))
                assay = escape_cue_string(ds.get("assay_type", ""))
                parts = [f'title: "{title}"']
                if species:
                    parts.append(f'species: "{species}"')
                if assay:
                    parts.append(f'assay_type: "{assay}"')
                lines.append(f"\t\t{{{', '.join(parts)}}},")
            lines.append(f"\t]")
        else:
            lines.append(f"\tfacebase_datasets: []")

        lines.append("}")
        lines.append("")

    return "\n".join(lines)


def main():
    cache = load_cache()
    use_api = True

    # Quick connectivity check: try one gene first
    print(f"from_facebase: checking DERIVA API connectivity...")
    test_result = fetch_datasets("SOX9")
    if test_result is None:
        print("  API unreachable — using bundled cache.", file=sys.stderr)
        use_api = False
    else:
        print(f"  API reachable ({len(test_result)} SOX9 datasets). Querying all genes...")

    gene_data = {}

    for i, symbol in enumerate(sorted(GENES.keys()), 1):
        print(f"  [{i:2d}/{len(GENES)}] {symbol}...", end=" ")

        datasets = None
        if use_api:
            raw = fetch_datasets(symbol)
            if raw is not None:
                datasets = [normalize_dataset(ds) for ds in raw[:MAX_DATASETS]]
            time.sleep(SLEEP_SEC)

        # Fall back to cache if API returned nothing or failed
        if datasets is None and symbol in cache:
            datasets = cache[symbol].get("datasets", [])[:MAX_DATASETS]
            print(f"(cache) ", end="")

        if not datasets:
            print("no datasets")
            continue

        # Use the first dataset's accession as the primary facebase_id
        facebase_id = datasets[0].get("accession", datasets[0].get("RID", ""))

        gene_data[symbol] = {
            "facebase_id": facebase_id,
            "datasets": datasets,
        }
        print(f"{len(datasets)} datasets")

    # Write CUE output
    cue_content = format_cue(gene_data)
    output = os.path.normpath(OUTPUT_PATH)
    os.makedirs(os.path.dirname(output), exist_ok=True)
    with open(output, "w") as f:
        f.write(cue_content)

    total_ds = sum(len(g["datasets"]) for g in gene_data.values())
    print(f"\nWrote {output} ({len(gene_data)} genes, {total_ds} total datasets)")


if __name__ == "__main__":
    main()
