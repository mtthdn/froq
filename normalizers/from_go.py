#!/usr/bin/env python3
"""
Normalizer: Gene Ontology (QuickGO REST API) -> model/go.cue

Queries the EBI QuickGO annotation search endpoint for each gene's UniProt
accession (human, taxon 9606). Deduplicates GO terms by term_id, resolves
term names via the QuickGO ontology endpoint, and writes a CUE file that
unifies with the shared schema.

Source-owned fields:
  - _in_go: true
  - go_id: UniProtKB accession
  - go_terms: [{term_id, term_name, aspect}, ...]
"""

import os
import sys
import time
import requests

# Resolve import path for sibling module
sys.path.insert(0, os.path.dirname(__file__))
from genes import GENES

QUICKGO_ANNOTATION_URL = "https://www.ebi.ac.uk/QuickGO/services/annotation/search"
QUICKGO_TERM_URL = "https://www.ebi.ac.uk/QuickGO/services/ontology/go/terms"
TAXON_ID = "9606"
LIMIT = 100
SLEEP_SEC = 0.5
TERM_BATCH_SIZE = 200  # QuickGO allows up to ~200 IDs per request

ASPECT_MAP = {
    "molecular_function": "F",
    "biological_process": "P",
    "cellular_component": "C",
}

OUTPUT_PATH = os.path.join(os.path.dirname(__file__), "..", "model", "go.cue")


def fetch_go_annotations(uniprot_id: str) -> list[dict] | None:
    """Fetch GO annotations for a UniProt accession from QuickGO."""
    params = {
        "geneProductId": uniprot_id,
        "taxonId": TAXON_ID,
        "limit": LIMIT,
    }
    headers = {"Accept": "application/json"}
    try:
        resp = requests.get(
            QUICKGO_ANNOTATION_URL, params=params, headers=headers, timeout=30
        )
        resp.raise_for_status()
        data = resp.json()
        return data.get("results", [])
    except requests.RequestException as e:
        print(f"  WARNING: API error for {uniprot_id}: {e}", file=sys.stderr)
        return None


def fetch_term_names(term_ids: list[str]) -> dict[str, str]:
    """Batch-resolve GO term IDs to human-readable names via QuickGO ontology."""
    name_map: dict[str, str] = {}
    headers = {"Accept": "application/json"}

    for i in range(0, len(term_ids), TERM_BATCH_SIZE):
        batch = term_ids[i : i + TERM_BATCH_SIZE]
        url = f"{QUICKGO_TERM_URL}/{','.join(batch)}"
        try:
            resp = requests.get(url, headers=headers, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            for entry in data.get("results", []):
                name_map[entry["id"]] = entry.get("name", "")
        except requests.RequestException as e:
            print(f"  WARNING: term lookup failed for batch: {e}", file=sys.stderr)

        if i + TERM_BATCH_SIZE < len(term_ids):
            time.sleep(SLEEP_SEC)

    return name_map


def deduplicate_terms(results: list[dict]) -> list[dict]:
    """Deduplicate GO terms by term_id, keeping first occurrence."""
    seen = set()
    terms = []
    for r in results:
        go_id = r.get("goId", "")
        if go_id in seen:
            continue
        seen.add(go_id)
        aspect_raw = r.get("goAspect", "")
        aspect = ASPECT_MAP.get(aspect_raw, aspect_raw)
        terms.append({
            "term_id": go_id,
            "term_name": "",  # resolved later via batch lookup
            "aspect": aspect,
        })
    return terms


def escape_cue_string(s: str | None) -> str:
    """Escape a string for CUE literal embedding."""
    if s is None:
        return ""
    return s.replace("\\", "\\\\").replace('"', '\\"')


def format_cue(gene_data: dict[str, dict]) -> str:
    """Format the collected gene data as a CUE file."""
    lines = [
        "package lacuene",
        "",
        "// Gene Ontology annotations from QuickGO (EBI).",
        "// Auto-generated by normalizers/from_go.py â€” do not hand-edit.",
        "",
    ]

    for symbol in sorted(gene_data.keys()):
        entry = gene_data[symbol]
        lines.append(f'genes: "{symbol}": {{')
        lines.append(f"\t_in_go: true")
        lines.append(f'\tgo_id:  "{escape_cue_string(entry["go_id"])}"')

        terms = entry["go_terms"]
        if terms:
            lines.append(f"\tgo_terms: [")
            for t in terms:
                tid = escape_cue_string(t["term_id"])
                tname = escape_cue_string(t["term_name"])
                asp = escape_cue_string(t["aspect"])
                lines.append(
                    f'\t\t{{term_id: "{tid}", term_name: "{tname}", aspect: "{asp}"}},'
                )
            lines.append(f"\t]")
        else:
            lines.append(f"\tgo_terms: []")

        lines.append("}")
        lines.append("")

    return "\n".join(lines)


def main():
    print(f"from_go: querying QuickGO for {len(GENES)} genes...")
    gene_data = {}

    for i, (symbol, ids) in enumerate(sorted(GENES.items()), 1):
        uniprot_id = ids["uniprot"]
        print(f"  [{i:2d}/{len(GENES)}] {symbol} ({uniprot_id})...", end=" ")

        results = fetch_go_annotations(uniprot_id)
        if results is None:
            print("SKIPPED (API error)")
            continue

        terms = deduplicate_terms(results)
        gene_data[symbol] = {
            "go_id": uniprot_id,
            "go_terms": terms,
        }
        print(f"{len(terms)} terms")

        if i < len(GENES):
            time.sleep(SLEEP_SEC)

    # Collect all unique GO term IDs across all genes for batch name resolution
    all_term_ids = sorted(
        {t["term_id"] for g in gene_data.values() for t in g["go_terms"]}
    )
    print(f"\nResolving {len(all_term_ids)} unique GO term names...", end=" ")
    name_map = fetch_term_names(all_term_ids)
    print(f"got {len(name_map)} names")

    # Backfill term names
    for g in gene_data.values():
        for t in g["go_terms"]:
            t["term_name"] = name_map.get(t["term_id"], "")

    # Write CUE output
    cue_content = format_cue(gene_data)
    output = os.path.normpath(OUTPUT_PATH)
    os.makedirs(os.path.dirname(output), exist_ok=True)
    with open(output, "w") as f:
        f.write(cue_content)

    print(f"Wrote {output} ({len(gene_data)} genes, "
          f"{sum(len(g['go_terms']) for g in gene_data.values())} total GO terms)")


if __name__ == "__main__":
    main()
