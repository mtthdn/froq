#!/usr/bin/env python3
"""
HPO normalizer: downloads Human Phenotype Ontology gene-phenotype annotations,
filters for the 20 neural crest genes, and writes model/hpo.cue.

Source: http://purl.obolibrary.org/obo/hp/hpoa/genes_to_phenotype.txt
Columns: ncbi_gene_id, gene_symbol, hpo_id, hpo_name, frequency, disease_id
"""

import csv
import os
import sys
import urllib.request
from collections import defaultdict
from pathlib import Path

# Resolve paths relative to repo root (parent of normalizers/)
REPO_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(REPO_ROOT / "normalizers"))

from genes import GENES, NCBI_TO_SYMBOL

HPO_URL = "http://purl.obolibrary.org/obo/hp/hpoa/genes_to_phenotype.txt"
HPO_DIR = REPO_ROOT / "data" / "hpo"
HPO_FILE = HPO_DIR / "genes_to_phenotype.txt"
OUTPUT_FILE = REPO_ROOT / "model" / "hpo.cue"


def download_if_missing() -> Path:
    """Download the HPO genes_to_phenotype.txt if not already cached."""
    if HPO_FILE.exists():
        print(f"  cached: {HPO_FILE}")
        return HPO_FILE

    HPO_DIR.mkdir(parents=True, exist_ok=True)
    print(f"  downloading {HPO_URL} ...")
    urllib.request.urlretrieve(HPO_URL, HPO_FILE)
    print(f"  saved: {HPO_FILE}")
    return HPO_FILE


def parse_annotations(path: Path) -> dict[str, set[str]]:
    """
    Parse HPO gene-phenotype file and return {gene_symbol: {phenotype_names}}.

    Only includes genes present in our GENES dict, matched by NCBI gene ID.
    """
    phenotypes_by_gene: dict[str, set[str]] = defaultdict(set)

    with open(path, "r", encoding="utf-8") as f:
        reader = csv.reader(f, delimiter="\t")
        header = next(reader)  # skip header line

        for row in reader:
            if len(row) < 4:
                continue

            ncbi_id = row[0].strip()
            hpo_name = row[3].strip()

            # Only keep genes in our canonical list
            symbol = NCBI_TO_SYMBOL.get(ncbi_id)
            if symbol is None:
                continue

            if hpo_name:
                phenotypes_by_gene[symbol].add(hpo_name)

    return phenotypes_by_gene


def escape_cue_string(s: str) -> str:
    """Escape a string for CUE literal output."""
    return s.replace("\\", "\\\\").replace('"', '\\"')


def write_cue(phenotypes_by_gene: dict[str, set[str]]) -> None:
    """Write model/hpo.cue with HPO phenotype data."""
    lines = [
        "package lacuene",
        "",
        "// HPO: Human Phenotype Ontology gene-phenotype annotations.",
        "// Source: http://purl.obolibrary.org/obo/hp/hpoa/genes_to_phenotype.txt",
        "// Generated by normalizers/from_hpo.py -- do not edit.",
        "",
        "genes: {",
    ]

    # Process genes in sorted order for deterministic output
    for symbol in sorted(phenotypes_by_gene.keys()):
        phenos = sorted(phenotypes_by_gene[symbol])
        ncbi_id = GENES[symbol]["ncbi"]

        lines.append(f'\t"{symbol}": {{')
        lines.append(f"\t\t_in_hpo:      true")
        lines.append(f'\t\thpo_gene_id:  "{ncbi_id}"')

        # Build phenotypes list
        lines.append(f"\t\tphenotypes: [")
        for p in phenos:
            lines.append(f'\t\t\t"{escape_cue_string(p)}",')
        lines.append(f"\t\t]")

        lines.append(f"\t}}")

    lines.append("}")
    lines.append("")  # trailing newline

    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_FILE.write_text("\n".join(lines), encoding="utf-8")
    print(f"  wrote {OUTPUT_FILE} ({len(phenotypes_by_gene)} genes)")


def main():
    print("from_hpo: downloading HPO annotations...")
    path = download_if_missing()

    print("from_hpo: parsing gene-phenotype annotations...")
    phenotypes_by_gene = parse_annotations(path)

    print(f"from_hpo: found {len(phenotypes_by_gene)} genes with HPO data")
    for symbol in sorted(phenotypes_by_gene.keys()):
        print(f"  {symbol}: {len(phenotypes_by_gene[symbol])} phenotypes")

    print("from_hpo: writing model/hpo.cue...")
    write_cue(phenotypes_by_gene)

    print("from_hpo: done.")


if __name__ == "__main__":
    main()
