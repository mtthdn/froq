#!/usr/bin/env python3
"""
Normalizer: AlphaFold + PDB -> model/structures.cue

Queries the AlphaFold prediction API and RCSB PDB search API for each
of the 95 neural crest genes, extracting protein structure availability:
  - AlphaFold prediction existence and confidence (meanPlddt)
  - PDB experimental structure count

Results are cached in data/structures/structures_cache.json for reproducibility.

Usage:
    python3 normalizers/from_structures.py
"""

import json
import sys
import time
from pathlib import Path

# Resolve paths relative to repo root (parent of normalizers/)
REPO_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(REPO_ROOT / "normalizers"))

from genes import GENES
from pipeline import PipelineReport
from utils import fetch_json_with_retry, post_json_with_retry

CACHE_DIR = REPO_ROOT / "data" / "structures"
CACHE_FILE = CACHE_DIR / "structures_cache.json"
OUTPUT_FILE = REPO_ROOT / "model" / "structures.cue"

ALPHAFOLD_API_URL = "https://alphafold.ebi.ac.uk/api/prediction"
PDB_SEARCH_URL = "https://search.rcsb.org/rcsbsearch/v2/query"

REQUEST_DELAY = 0.3  # seconds between requests


def fetch_alphafold(uniprot_id: str) -> dict | None:
    """
    Query AlphaFold API for a UniProt accession. Returns dict with:
      - has_alphafold: True
      - confidence: meanPlddt score (0-100)
    Or None on failure.
    """
    url = f"{ALPHAFOLD_API_URL}/{uniprot_id}"

    try:
        data = fetch_json_with_retry(
            url,
            headers={"Accept": "application/json"},
        )
    except Exception as e:
        print(f"  WARNING: AlphaFold request failed for {uniprot_id}: {e}", file=sys.stderr)
        return None

    # AlphaFold API returns a list of predictions
    if isinstance(data, list) and len(data) > 0:
        entry = data[0]
        # globalMetricValue is the mean pLDDT confidence score (0-100)
        confidence = entry.get("globalMetricValue")
        return {
            "has_alphafold": True,
            "confidence": confidence,
        }
    elif isinstance(data, dict):
        confidence = data.get("globalMetricValue")
        return {
            "has_alphafold": True,
            "confidence": confidence,
        }

    return None


def fetch_pdb_count(uniprot_id: str) -> int | None:
    """
    Query RCSB PDB search API for structures matching a UniProt accession.
    Returns count of PDB entries, or None on failure.
    """
    query_body = {
        "query": {
            "type": "terminal",
            "service": "text",
            "parameters": {
                "attribute": "rcsb_polymer_entity_container_identifiers.reference_sequence_identifiers.database_accession",
                "operator": "exact_match",
                "value": uniprot_id,
            },
        },
        "return_type": "entry",
        "request_options": {"return_all_hits": True},
    }

    try:
        data = post_json_with_retry(
            PDB_SEARCH_URL,
            json_body=query_body,
            headers={"Accept": "application/json"},
        )
    except Exception as e:
        # PDB returns 204 (no content) when no results found
        # and some HTTP errors for no matches
        err_str = str(e)
        if "204" in err_str or "404" in err_str:
            return 0
        print(f"  WARNING: PDB request failed for {uniprot_id}: {e}", file=sys.stderr)
        return None

    if isinstance(data, dict):
        total = data.get("total_count", 0)
        return total

    return 0


def load_cache() -> dict:
    """Load cached structures data if available."""
    if CACHE_FILE.exists():
        with open(CACHE_FILE) as f:
            return json.load(f)
    return {}


def save_cache(cache: dict) -> None:
    """Persist the structures cache to disk."""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    with open(CACHE_FILE, "w") as f:
        json.dump(cache, f, indent=2, sort_keys=True)
    print(f"  cached: {CACHE_FILE}")


def format_score(value) -> str | None:
    """Format a numeric score for CUE output, or return None if None."""
    if value is None:
        return None
    return f"{float(value):.1f}"


def generate_cue(structures_data: dict) -> str:
    """Generate CUE source from structures data, keyed by HGNC symbol."""
    gene_count = len(structures_data)
    lines = [
        "package lacuene",
        "",
        "// Protein structures: AlphaFold predictions + PDB experimental structures.",
        "// Sources: AlphaFold EBI API, RCSB PDB Search API",
        f"// Generated by normalizers/from_structures.py -- {gene_count} genes",
        "",
        "genes: {",
    ]

    for symbol in sorted(structures_data.keys()):
        entry = structures_data[symbol]
        has_af = entry.get("has_alphafold", False)
        confidence = entry.get("confidence")
        pdb_count = entry.get("pdb_count", 0)
        has_experimental = pdb_count > 0

        lines.append(f'\t"{symbol}": {{')
        lines.append(f"\t\t_in_structures: true")
        lines.append(f"\t\thas_alphafold: {str(has_af).lower()}")

        conf_str = format_score(confidence)
        if conf_str is not None:
            lines.append(f"\t\talphafold_confidence: {conf_str}")

        lines.append(f"\t\tpdb_count: {pdb_count}")
        lines.append(f"\t\thas_experimental_structure: {str(has_experimental).lower()}")

        lines.append(f"\t}}")

    lines.append("}")
    lines.append("")  # trailing newline

    return "\n".join(lines)


def main():
    report = PipelineReport("from_structures")
    print("from_structures: querying AlphaFold + PDB for neural crest gene structures...")

    cache = load_cache()
    structures_data = {}
    fetched = 0
    cached_count = 0
    failed = 0

    for symbol in sorted(GENES.keys()):
        uniprot_id = GENES[symbol].get("uniprot", "")
        if not uniprot_id:
            print(f"  {symbol}: no UniProt ID, skipping", file=sys.stderr)
            report.skipped(symbol, "no UniProt ID")
            continue

        if symbol in cache:
            entry = cache[symbol]
            af_str = "AlphaFold" if entry.get("has_alphafold") else "no AF"
            pdb_str = f"{entry.get('pdb_count', 0)} PDB"
            print(f"  {symbol}: cached ({af_str}, {pdb_str})")
            structures_data[symbol] = entry
            report.cached(symbol, f"{af_str}, {pdb_str}")
            cached_count += 1
            continue

        print(f"  {symbol}: querying AlphaFold + PDB ({uniprot_id})...", end=" ", flush=True)

        # Fetch AlphaFold data
        af_result = fetch_alphafold(uniprot_id)
        time.sleep(REQUEST_DELAY)

        # Fetch PDB count
        pdb_count = fetch_pdb_count(uniprot_id)
        time.sleep(REQUEST_DELAY)

        if af_result is None and pdb_count is None:
            print("FAILED (skipping)", file=sys.stderr)
            report.failed(symbol, "both APIs returned no data")
            failed += 1
            continue

        has_af = af_result is not None and af_result.get("has_alphafold", False)
        confidence = af_result.get("confidence") if af_result else None
        pdb = pdb_count if pdb_count is not None else 0

        result = {
            "has_alphafold": has_af,
            "confidence": confidence,
            "pdb_count": pdb,
        }

        af_str = f"pLDDT={confidence:.1f}" if confidence is not None else ("AlphaFold" if has_af else "no AF")
        pdb_str = f"{pdb} PDB"
        print(f"{af_str}, {pdb_str}")

        structures_data[symbol] = result
        cache[symbol] = result
        report.ok(symbol, f"{af_str}, {pdb_str}")
        fetched += 1

    # Save updated cache
    save_cache(cache)

    if not structures_data:
        print("ERROR: no structure data retrieved for any gene", file=sys.stderr)
        sys.exit(1)

    # Write CUE output
    print("from_structures: writing model/structures.cue...")
    cue_source = generate_cue(structures_data)
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_FILE, "w") as f:
        f.write(cue_source)

    # Stats
    has_af = sum(1 for d in structures_data.values() if d.get("has_alphafold"))
    has_pdb = sum(1 for d in structures_data.values() if d.get("pdb_count", 0) > 0)

    print(f"from_structures: wrote {OUTPUT_FILE}")
    print(f"  {len(structures_data)} genes, {has_af} with AlphaFold, {has_pdb} with PDB structures")
    print(f"  ({fetched} fetched, {cached_count} cached, {failed} failed)")
    print(report.summary())


if __name__ == "__main__":
    main()
